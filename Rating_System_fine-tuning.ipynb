{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e3eeaf-4ac3-4f98-904e-376b2a035f46",
   "metadata": {},
   "source": [
    "# Importing Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a524bdf-7d20-4b38-ac83-a080e023888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\alaa_ai_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5735369e-c5bd-47c3-ac65-0c63926d2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8f137c-8416-4903-b13e-9173b684bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce7ce3-c421-439f-86b0-ac0ace0ae815",
   "metadata": {},
   "source": [
    "# Base Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea66f5-9dba-4134-a6b1-79733a8f128e",
   "metadata": {},
   "source": [
    "Next, we load in our base model. The base model here is a relatively small one, but there are several other (larger) ones that we could have used (e.g. roberta-base, llama2, gpt2). A full list is available here.\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4f03cc-4499-4eb9-ae96-9a6cc0296dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "# define label maps\n",
    "id2label = {0: \"Zero\", 1: \"One\" , 2: \"Two\"}\n",
    "label2id = {\"Zero\":0, \"One\":1 , \"Two\": 2}\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=3, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665613f7-55db-448a-8754-dcbecd16bd72",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c0884a-f323-40b4-a1ef-dede30c39c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup</td>\n",
       "      <td>cup (s)</td>\n",
       "      <td>0</td>\n",
       "      <td>Zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup</td>\n",
       "      <td>bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>Zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cup</td>\n",
       "      <td>We calibrate with it</td>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>It is placed with a cup of coffee</td>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup</td>\n",
       "      <td>We drink in it</td>\n",
       "      <td>2</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic                                text  label label_str\n",
       "0   cup                             cup (s)      0      Zero\n",
       "1   cup                              bottle      0      Zero\n",
       "2   cup                We calibrate with it      1       One\n",
       "3   cup   It is placed with a cup of coffee      1       One\n",
       "4   cup                      We drink in it      2       Two"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data set from huggingface\n",
    "df = pd.read_csv('ratings.csv' ,  encoding='unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d1d1a0-74b8-4880-a247-221a66de2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "df=df.drop(['Topic','label_str'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060fdd6d-d0bb-4eb4-86b2-5e7028f04482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup (s)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bottle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We calibrate with it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is placed with a cup of coffee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We drink in it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text  label\n",
       "0                             cup (s)      0\n",
       "1                              bottle      0\n",
       "2                We calibrate with it      1\n",
       "3   It is placed with a cup of coffee      1\n",
       "4                      We drink in it      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd13162-c510-492b-ac73-8b452d64c673",
   "metadata": {},
   "source": [
    "# Convert our Dataset to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39a8a3b-9467-4095-b068-5b9089236318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('train.parquet', engine='fastparquet')\n",
    "df.to_parquet('test.parquet', engine='fastparquet')\n",
    "df.to_parquet('validation.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5691ae39-1aed-4b0c-8367-298e6a652303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Definition of the topic', 'Rating'],\n",
       "    num_rows: 480\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to dataset object\n",
    "# dataset = ds.dataset(pa.Table.from_pandas(df).to_batches())\n",
    "# dataset = Dataset(pa.Table.from_pandas(df))\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889c9d4d-6256-4b5f-bed5-1035d56e696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 480 examples [00:00, 96213.43 examples/s]\n",
      "Generating validation split: 480 examples [00:00, 160113.40 examples/s]\n",
      "Generating test split: 480 examples [00:00, 120108.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load dataset\n",
    "# dataset = load_dataset(\"alaatiger989/rating_system\")\n",
    "dataset = load_dataset(\"data\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b277c-2160-4c12-9e6d-ea195c553c09",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc388f-07ce-4d4b-b71b-c051eb6fed2e",
   "metadata": {},
   "source": [
    "Next, we need to preprocess our data so that it can be used for training. This consists of using a tokenizer to convert the text into an integer representation understood by the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d356fa-b9ce-438a-b8d8-f2ebd5098a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd3f83-4fb9-4e8c-8238-e9ab854984a7",
   "metadata": {},
   "source": [
    "To apply the tokenizer to the dataset, we use the .map() method. This takes in a custom function that specifies how the text should be preprocessed. In this case, that function is called tokenize_function(). In addition to translating text to integers, this function truncates integer sequences such that they are no longer than 512 numbers to conform to the base model’s max input length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c14fc4c3-03b1-4dcd-ab85-0fdd100ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb48a4cd-dfe9-4e55-925a-4edfbb3caf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6329752c-1207-49a3-b2e8-fff6c8bd960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 480/480 [00:00<00:00, 22869.19 examples/s]\n",
      "Map: 100%|██████████| 480/480 [00:00<00:00, 25258.33 examples/s]\n",
      "Map: 100%|██████████| 480/480 [00:00<00:00, 28221.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 480\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7809ef4-811b-4704-b6ab-5932130b06a5",
   "metadata": {},
   "source": [
    "At this point, we can also create a data collator, which will dynamically pad examples in each batch during training such that they all have the same length. This is computationally more efficient than padding all examples to be equal in length across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086990b6-3e37-4494-b3fc-af470f12fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0c797-7d63-436f-8946-010e92cedb10",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5816612-e350-4f3d-974f-59186d6c19d8",
   "metadata": {},
   "source": [
    "We can define how we want to evaluate our fine-tuned model via a custom function. Here, we define the compute_metrics() function to compute the model’s accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8835eab8-326d-46a3-ba28-ed582dfc9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ba6118-320e-497e-8e94-2c93224f027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, \n",
    "                                          references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ba643-aa9a-49e4-b488-24370dd519f0",
   "metadata": {},
   "source": [
    "# Untrained model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839011e4-9dea-47f8-91c6-0676991b556b",
   "metadata": {},
   "source": [
    "Before training our model, we can evaluate how the base model with a randomly initialized classification head performs on some example inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e43d266-830b-4f28-acd2-956dc9f00da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      " It is placed with a cup of coffee. - Zero\n",
      "Something for a girl to cover her hair with. - Zero\n",
      "pet that we can raise at home. - Zero\n",
      "He runs and drinks. - Zero\n",
      "Floating. - Zero\n"
     ]
    }
   ],
   "source": [
    "# define list of examples\n",
    "text_list = [\" It is placed with a cup of coffee.\", \"Something for a girl to cover her hair with.\", \n",
    "\"pet that we can raise at home.\", \"He runs and drinks.\", \n",
    "\"Floating.\"]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "for text in text_list:\n",
    "    # tokenize text\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    # compute logits\n",
    "    logits = model(inputs).logits\n",
    "    # convert logits to label\n",
    "    predictions = torch.argmax(logits)\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c6c97-4250-4b4c-b812-f9acbdb09af1",
   "metadata": {},
   "source": [
    "As expected, the model performance is equivalent to random guessing. Let’s see how we can improve this with fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f74056-83e1-4362-b354-80f22edcb425",
   "metadata": {},
   "source": [
    "# Fine-tuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e8195-94f9-4c3e-8c96-65f5cadbc565",
   "metadata": {},
   "source": [
    "To use LoRA for fine-tuning, we first need a config file. This sets all the parameters for the LoRA algorithm. See comments in the code block for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d668a122-ba0b-4017-932d-4078da804e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", # sequence classification\n",
    "                        r=4, # intrinsic rank of trainable weight matrix\n",
    "                        lora_alpha=32, # this is like a learning rate\n",
    "                        lora_dropout=0.01, # probablity of dropout\n",
    "                        target_modules = ['q_lin']) # we apply lora to query layer only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b634df9-f9b8-4bfd-b80b-bc789c458ad2",
   "metadata": {},
   "source": [
    "We can then create a new version of our model that can be trained via PEFT. Notice that the scale of trainable parameters was reduced by about 100x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "febbd9d3-22ff-45f3-a962-8be9e7cbeb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 629,763 || all params: 67,585,542 || trainable%: 0.9318013607111414\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d0157-fc65-4878-af0b-fe671e70077e",
   "metadata": {},
   "source": [
    "Next, we define hyperparameters for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b624c57-022b-4461-90fa-7d531594cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3 # size of optimization step \n",
    "batch_size = 4 # number of examples processed per optimziation step\n",
    "num_epochs = 10 # number of times model runs through training data\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878614ce-e46d-4ab4-a338-450fd209164c",
   "metadata": {},
   "source": [
    "Finally, we create a trainer() object and fine-tune the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76693c1-abf7-435a-86d2-cfe304c2b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\alaa_ai_env\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model, # our peft model\n",
    "    args=training_args, # hyperparameters\n",
    "    train_dataset=tokenized_dataset[\"train\"], # training data\n",
    "    eval_dataset=tokenized_dataset[\"validation\"], # validation data\n",
    "    tokenizer=tokenizer, # define tokenizer\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics, # evaluates model using compute_metrics() function from before\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fc62677-e45e-44f8-bdd3-bb4c4724ab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 13:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.907722</td>\n",
       "      <td>{'accuracy': 0.5666666666666667}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.746477</td>\n",
       "      <td>{'accuracy': 0.65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483096</td>\n",
       "      <td>{'accuracy': 0.8333333333333334}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286496</td>\n",
       "      <td>{'accuracy': 0.8958333333333334}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>0.221522</td>\n",
       "      <td>{'accuracy': 0.9125}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>0.170207</td>\n",
       "      <td>{'accuracy': 0.94375}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>0.092014</td>\n",
       "      <td>{'accuracy': 0.9625}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.839900</td>\n",
       "      <td>0.095509</td>\n",
       "      <td>{'accuracy': 0.9604166666666667}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.067267</td>\n",
       "      <td>{'accuracy': 0.975}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.065783</td>\n",
       "      <td>{'accuracy': 0.9770833333333333}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.5085150941212973, metrics={'train_runtime': 808.148, 'train_samples_per_second': 5.94, 'train_steps_per_second': 1.485, 'total_flos': 13236732637920.0, 'train_loss': 0.5085150941212973, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a73c4-b770-4c5a-b608-dcac1ca160af",
   "metadata": {},
   "source": [
    "# Trained model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890c4e1-a773-48d4-8bb3-a7b6d20bde5e",
   "metadata": {},
   "source": [
    "To see how the model performance has improved, let’s apply it to the same 5 examples from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0a2602f-6210-4f0a-a3ee-5e6f968e8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have an NVIDIA GPU attached, use 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    # If Apple Silicon, set to 'mps' - otherwise 'cpu' (not advised)\n",
    "    try:\n",
    "        device = torch.device('mps')\n",
    "    except Exception:\n",
    "        device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6efa9135-bd10-4129-8be9-4fac460e2194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=3, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device) # moving to mps for Mac (can alternatively do 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ab06b9-0a33-44be-ab9d-1e1686193add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n",
      " It is placed with a cup of coffee. - One\n",
      "Something for a girl to cover her hair with. - Two\n",
      "pet that we can raise at home. - Two\n",
      "He runs and drinks. - Zero\n",
      "Floating. - Zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device) # moving to mps for Mac (can alternatively do 'cpu')\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6161f1-f3b3-494c-a22c-5f73352ee599",
   "metadata": {},
   "source": [
    "The fine-tuned model improved significantly from its prior random guessing, correctly classifying all but one of the examples in the above code. This aligns with the ~90% accuracy metric we saw during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
